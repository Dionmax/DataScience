{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 14:43:38.774765: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736433818.790535   34100 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736433818.795048   34100 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-09 14:43:38.812019: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# conda install conda-forge::transformers\n",
    "# conda install conda-forge/label/cf202003::transformers\n",
    "import transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.5501401424407959, 'token': 8105, 'token_str': 'chão', 'sequence': 'Existe uma chance do corpo cair no chão.'}\n",
      "\n",
      "{'score': 0.060237910598516464, 'token': 528, 'token_str': 'mar', 'sequence': 'Existe uma chance do corpo cair no mar.'}\n",
      "\n",
      "{'score': 0.0318361297249794, 'token': 11334, 'token_str': 'sono', 'sequence': 'Existe uma chance do corpo cair no sono.'}\n",
      "\n",
      "{'score': 0.025314774364233017, 'token': 2187, 'token_str': 'rio', 'sequence': 'Existe uma chance do corpo cair no rio.'}\n",
      "\n",
      "{'score': 0.022480688989162445, 'token': 15213, 'token_str': 'buraco', 'sequence': 'Existe uma chance do corpo cair no buraco.'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mascarar = pipeline('fill-mask', model='neuralmind/bert-base-portuguese-cased')\n",
    "\n",
    "text = mascarar(\"Existe uma chance do corpo cair no [MASK].\")\n",
    "\n",
    "for i in text:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.2569027543067932, 'token': 18116, 'token_str': 'Excel', 'sequence': 'O Excel é a melhor linguagem de programação.'}\n",
      "\n",
      "{'score': 0.18987949192523956, 'token': 14104, 'token_str': 'Java', 'sequence': 'O Java é a melhor linguagem de programação.'}\n",
      "\n",
      "{'score': 0.05691041424870491, 'token': 16142, 'token_str': 'Flash', 'sequence': 'O Flash é a melhor linguagem de programação.'}\n",
      "\n",
      "{'score': 0.05418495088815689, 'token': 8306, 'token_str': 'Português', 'sequence': 'O Português é a melhor linguagem de programação.'}\n",
      "\n",
      "{'score': 0.04730049893260002, 'token': 2658, 'token_str': 'inglês', 'sequence': 'O inglês é a melhor linguagem de programação.'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = mascarar(\"O [MASK] é a melhor linguagem de programação.\")\n",
    "\n",
    "for i in text:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.48429611325263977, 'token': 1855, 'token_str': 'capital', 'sequence': 'Brasilia é a capital do Brasil.'}\n",
      "\n",
      "{'score': 0.059929244220256805, 'token': 1354, 'token_str': 'cara', 'sequence': 'Brasilia é a cara do Brasil.'}\n",
      "\n",
      "{'score': 0.048293206840753555, 'token': 9469, 'token_str': 'Capital', 'sequence': 'Brasilia é a Capital do Brasil.'}\n",
      "\n",
      "{'score': 0.030272433534264565, 'token': 8410, 'token_str': 'alma', 'sequence': 'Brasilia é a alma do Brasil.'}\n",
      "\n",
      "{'score': 0.01774604618549347, 'token': 2196, 'token_str': 'mãe', 'sequence': 'Brasilia é a mãe do Brasil.'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = mascarar(\"Brasilia é a [MASK] do Brasil.\")\n",
    "\n",
    "for i in text:\n",
    "    print(i)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
